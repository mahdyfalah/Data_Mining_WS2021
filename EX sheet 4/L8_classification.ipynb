{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HAM vs. SPAM Text Classification\n",
    "In this example we will perform email text classification and predict the category of an email as HAM or SPAM. We will use a dataset of emails and their categories that you can download from: https://www.kaggle.com/uciml/sms-spam-collection-dataset\n",
    "This is a binary discrimination task on which several classification algorithms reach high classification scores of over 90 % accuracy. We will try some of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# to ensure reproducibility of results depending on random factors\n",
    "sd = 7 ; np.random.seed(sd) ; random.seed(sd) ; os.environ['PYTHONHASHSEED'] = str(sd)\n",
    "\n",
    "# load the data from file into a pandas dataframe\n",
    "filepath = './spam.csv' ; df = pd.read_csv(filepath, encoding='latin-1')\n",
    "# print the length of the dataset \n",
    "print(\"Number of documents: \", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove redundant columns\n",
    "df = df.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1)\n",
    "# rename valuable columns: email will contain the email texts, labels the category ham or spam\n",
    "df = df.rename(columns={'v1':'labels','v2': 'email'})\n",
    "# show first 5 rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add number of email characters in an extra \"length\" column\n",
    "df['length'] = df['email'].apply(len)\n",
    "\n",
    "# get an email as illustration example and print its text and category\n",
    "email7 = df['email'][6] ; label7 = df['labels'][6]\n",
    "print(\"Example text:  \", email7) ; print(\"Example class: \", label7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# text preprocessing: implement tokenization and stopword removal in a function\n",
    "# no lowercasing or punctuation removal since capitalization and symbols are important\n",
    "# features of SPAM emails\n",
    "def text_preprocess(sample):\n",
    "    stops = stopwords.words('english')  # english stopwords\n",
    "    words = word_tokenize(sample)  # word-level tokenization\n",
    "    clean = [word for word in words if word.lower() not in stops] # remove stopwords\n",
    "    return clean\n",
    "\n",
    "# print original email7 example\n",
    "print(\"Original example:\\n\", email7)\n",
    "\n",
    "# apply the preprocessing function to emails\n",
    "df['email'].apply(text_preprocess)\n",
    "\n",
    "# print preprocessed email7 example\n",
    "email7 = text_preprocess(email7)\n",
    "print(\"\\nProcessed example:\\n\", ' '.join(email7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# vectorize example email and whole set with count and tfidf vectorizers\n",
    "cv_transf = CountVectorizer()\n",
    "tfidf_transf = TfidfTransformer()\n",
    "cv_transf.fit(df['email'])\n",
    "cv_metrix = cv_transf.transform(df['email'])\n",
    "cv_email7 = cv_transf.transform(email7)\n",
    "tfidf_transf.fit(cv_metrix)\n",
    "tfidf_email7 = tfidf_transf.transform(cv_email7) \n",
    "tfidf_matrix = tfidf_transf.transform(cv_metrix)\n",
    "\n",
    "# split the entire dataset in train and test cuts: 85% and 15% respectively\n",
    "from sklearn.model_selection import train_test_split\n",
    "email_train, email_test, label_train, label_test = train_test_split(tfidf_matrix, \n",
    "                                            df['labels'], test_size=0.15)\n",
    "\n",
    "# 85 % training data and 15 % test data\n",
    "print(\"Train size: \", len(label_train))\n",
    "print(\"Test size: \", len(label_test))\n",
    "\n",
    "email_train, email_dev, label_train, label_dev = train_test_split(email_train, \n",
    "                                            label_train, test_size=0.10)\n",
    "\n",
    "# 8.5 % development part and 76.5 % training set and 15 % test set \n",
    "\n",
    "# print size of train and test cut\n",
    "print(\"\\nTrain size: \", len(label_train))\n",
    "print(\"Dev size: \", len(label_dev))\n",
    "print(\"Test size: \", len(label_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "# train a multinomial naive bayes model\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(email_train, label_train)\n",
    "\n",
    "# Train a K nearest neighbours classifier\n",
    "knn = KNeighborsClassifier().fit(email_train, label_train)\n",
    "\n",
    "# train a decision tree classifier\n",
    "dct = DecisionTreeClassifier().fit(email_train, label_train)\n",
    "\n",
    "# train a support vector classifier\n",
    "svc = svm.SVC().fit(email_train, label_train)\n",
    "\n",
    "# select one of the models\n",
    "model = svc\n",
    "\n",
    "# show prediction and actuall category of email7\n",
    "print('Email7 Prediction:', model.predict(tfidf_email7)[0])\n",
    "print('Email7 Expectation:', label7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all label predictions\n",
    "label_pred = model.predict(email_test)\n",
    "\n",
    "# compute and print accuracy for the given model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc = accuracy_score(label_test, label_pred)\n",
    "\n",
    "model_name = type(model).__name__\n",
    "print(\"Accuracy of model {} is: {:.4f}\".format(model_name, acc))"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "ninhu"
   }
  ],
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
